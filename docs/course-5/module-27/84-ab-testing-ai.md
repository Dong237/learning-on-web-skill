# Note 84: è¿­ä»£æ›´æ–°ä¸ABæµ‹è¯• | Iterative Updates & A/B Testing for AI

> **æœ¬èŠ‚ç›®æ ‡**: æŒæ¡AIäº§å“ABæµ‹è¯•ç‰¹æ®Šæ€§ï¼Œå¤šè‡‚è€è™æœºï¼ˆMABï¼‰ç®—æ³•åº”ç”¨ï¼Œç°åº¦å‘å¸ƒç­–ç•¥

---

## æ ¸å¿ƒæ¦‚å¿µé€Ÿè§ˆ

| æµ‹è¯•æ–¹æ³• | é€‚ç”¨åœºæ™¯ | ä¼˜åŠ¿ | å±€é™æ€§ |
|---------|---------|------|--------|
| **ä¼ ç»ŸABæµ‹è¯•** | æ˜ç¡®å‡è®¾ã€é•¿æœŸå†³ç­– | ç»Ÿè®¡ä¸¥è°¨ã€ç»“è®ºå¯é  | æµé‡æµªè´¹ã€å‘¨æœŸé•¿ |
| **å¤šè‡‚è€è™æœºï¼ˆMABï¼‰** | æŒç»­ä¼˜åŒ–ã€åŠ¨æ€åˆ†é… | æœ€å°åŒ–é—æ†¾å€¼ã€å®æ—¶è°ƒæ•´ | ç†è®ºå¤æ‚ã€éœ€å¤§æµé‡ |
| **ç°åº¦å‘å¸ƒï¼ˆCanaryï¼‰** | é£é™©å¯æ§çš„æ¨¡å‹ä¸Šçº¿ | å®‰å…¨ã€å¯å›æ»š | ç›‘æ§æˆæœ¬é«˜ |
| **ç‰¹å¾æ——å¸œï¼ˆFeature Flagsï¼‰** | å¿«é€Ÿå¼€å…³åŠŸèƒ½ | è§£è€¦éƒ¨ç½²ä¸å‘å¸ƒ | æŠ€æœ¯å€ºåŠ¡é£é™© |

**2026å¹´å…³é”®æ•°æ®**:
- **å­—èŠ‚è·³åŠ¨DataTester**: **240ä¸‡+** ABå®éªŒï¼Œ**4000+** æ–°å®éªŒ/å¤©ï¼Œ**5ä¸‡+** å¹¶å‘å®éªŒï¼ˆ[æ®å­—èŠ‚æ•°æ®å¹³å°](https://www.cnblogs.com/bytedata/p/17999746)ï¼‰
- **Thompson Sampling**: è¡Œä¸šæœ€æµè¡ŒMABç®—æ³•ï¼Œ**æ¸è¿‘æœ€ä¼˜**ï¼ˆ[æ®DoorDash 2025](https://careersatdoordash.com/blog/experimentation-at-doordash-with-a-multi-armed-bandit-platform/)ï¼‰
- **ç°åº¦å‘å¸ƒ**: **1%â†’5%â†’20%â†’100%** æ¸è¿›å¼ä¸Šçº¿ï¼Œè‡ªåŠ¨å›æ»šé˜ˆå€¼ï¼šå»¶è¿Ÿ+10% or è½¬åŒ–ç‡-1%ï¼ˆ[æ®Dataforest AI](https://dataforest.ai/glossary/canary-deployment)ï¼‰

---

## 1. AIäº§å“ABæµ‹è¯•çš„ç‰¹æ®Šæ€§

### 1.1 ä¼ ç»ŸAB vs AI AB

| ç»´åº¦ | ä¼ ç»Ÿäº§å“ABæµ‹è¯• | AIäº§å“ABæµ‹è¯• |
|------|--------------|-------------|
| **å˜é‡æ§åˆ¶** | UIé¢œè‰²ã€æ–‡æ¡ˆã€å¸ƒå±€ | æ¨¡å‹ç‰ˆæœ¬ã€Promptã€æ¸©åº¦å‚æ•° |
| **è¯„ä¼°å‘¨æœŸ** | 7-14å¤© | 3-7å¤©ï¼ˆæ¨¡å‹å¿«é€Ÿè¿­ä»£ï¼‰ |
| **æ ·æœ¬é‡è¦æ±‚** | ä¸­ç­‰ï¼ˆåƒçº§ï¼‰ | å¤§ï¼ˆä¸‡çº§ï¼ŒAIè¾“å‡ºéšæœºæ€§ï¼‰ |
| **æˆåŠŸæŒ‡æ ‡** | CTRã€è½¬åŒ–ç‡ | å¹»è§‰ç‡ã€CSATã€TTFTã€æˆæœ¬ |
| **å›æ»šå¤æ‚åº¦** | ä½ï¼ˆå‰ç«¯åˆ‡æ¢ï¼‰ | é«˜ï¼ˆæ¨¡å‹æ¨ç†åŸºç¡€è®¾æ–½ï¼‰ |
| **ç»Ÿè®¡æŒ‘æˆ˜** | Simpsonæ‚–è®º | éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆç”¨æˆ·ä¼šè¯ç›¸å…³ï¼‰ |

**æ¡ˆä¾‹**: é€šä¹‰åƒé—®Qwen3ä¸Šçº¿ABæµ‹è¯•

```yaml
å®éªŒè®¾è®¡:
  å¯¹ç…§ç»„Control: Qwen2.5-72B (å½“å‰ç”Ÿäº§æ¨¡å‹)
  å®éªŒç»„Treatment: Qwen3-Max (æ–°æ¨¡å‹)
  æµé‡åˆ†é…: 90% vs 10%
  è¯„ä¼°å‘¨æœŸ: 7å¤©

æˆåŠŸæŒ‡æ ‡(OEC):
  ä¸»æŒ‡æ ‡Primary:
    - å¹»è§‰ç‡ < 4.8%ï¼ˆæƒé‡40%ï¼‰
    - CSAT > 4.2/5ï¼ˆæƒé‡30%ï¼‰
  æ¬¡æŒ‡æ ‡Secondary:
    - TTFT < 2sï¼ˆæƒé‡20%ï¼‰
    - æˆæœ¬ < Â¥0.02/1K tokensï¼ˆæƒé‡10%ï¼‰

ç»Ÿè®¡æ˜¾è‘—æ€§:
  ç½®ä¿¡åº¦: 95%
  æœ€å°å¯æ£€æµ‹æ•ˆåº”MDE: 5%
  æ ·æœ¬é‡è®¡ç®—: N = (Z_Î±/2 + Z_Î²)Â² Ã— 2ÏƒÂ² / Î´Â²
    â†’  N â‰ˆ 15,000 ç”¨æˆ·/ç»„ï¼ˆå…±3ä¸‡ï¼‰

å®é™…ç»“æœ(7å¤©å):
  å¹»è§‰ç‡: 6.5% â†’ 4.8% âœ… (-26%)
  CSAT: 4.1 â†’ 4.3 âœ… (+4.9%)
  TTFT: 2.3s â†’ 1.9s âœ… (-17%)
  æˆæœ¬: Â¥0.018 â†’ Â¥0.015 âœ… (-17%)

å†³ç­–: å…¨é‡ä¸Šçº¿Qwen3-Maxï¼ˆå®éªŒç»„å…¨é¢ä¼˜äºå¯¹ç…§ç»„ï¼‰
```

### 1.2 AI ABæµ‹è¯•çš„7å¤§æŒ‘æˆ˜

**1. éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆNon-IIDï¼‰**
- **é—®é¢˜**: ç”¨æˆ·åŒä¸€ä¼šè¯å†…å¤šæ¬¡äº¤äº’ï¼Œæ•°æ®ä¸ç‹¬ç«‹
- **è§£å†³**: ä»¥**ç”¨æˆ·ä¸ºå•ä½**éšæœºåˆ†ç»„ï¼ˆè€Œéè¯·æ±‚çº§åˆ«ï¼‰

**2. é«˜æ–¹å·®ï¼ˆHigh Varianceï¼‰**
- **é—®é¢˜**: LLMè¾“å‡ºéšæœºæ€§å¤§ï¼ˆç›¸åŒPromptä¸åŒå“åº”ï¼‰
- **è§£å†³**: å¢å¤§æ ·æœ¬é‡ã€ä½¿ç”¨**CUPEDæ–¹å·®ç¼©å‡**æŠ€æœ¯

**3. é•¿æœŸæ•ˆåº”ï¼ˆLong-term Effectsï¼‰**
- **é—®é¢˜**: ç”¨æˆ·å¯¹æ–°æ¨¡å‹ä¹ æƒ¯éœ€è¦æ—¶é—´ï¼ˆæ–°å¥‡æ•ˆåº” vs ä¹ æƒ¯æ•ˆåº”ï¼‰
- **è§£å†³**: å»¶é•¿æµ‹è¯•å‘¨æœŸè‡³**14å¤©**ï¼Œè§‚å¯Ÿç•™å­˜ç‡è¶‹åŠ¿

**4. å¤šç›®æ ‡ä¼˜åŒ–ï¼ˆMulti-objectiveï¼‰**
- **é—®é¢˜**: å‡†ç¡®ç‡ã€å»¶è¿Ÿã€æˆæœ¬ä¸‰è€…trade-off
- **è§£å†³**: åŠ æƒOECï¼ˆOverall Evaluation Criterionï¼‰

**5. ç½‘ç»œæ•ˆåº”ï¼ˆNetwork Effectsï¼‰**
- **é—®é¢˜**: ç¤¾äº¤äº§å“ä¸­ï¼Œå®éªŒç»„ç”¨æˆ·å½±å“å¯¹ç…§ç»„ç”¨æˆ·
- **è§£å†³**: **é›†ç¾¤éšæœºåŒ–**ï¼ˆCluster Randomizationï¼‰ï¼ŒæŒ‰ç¤¾äº¤å›¾åˆ†ç»„

**6. è¾›æ™®æ£®æ‚–è®ºï¼ˆSimpson's Paradoxï¼‰**
- **é—®é¢˜**: åˆ†å±‚æ•°æ®ä¸­æ•´ä½“è¶‹åŠ¿ä¸å­ç»„è¶‹åŠ¿ç›¸å
- **è§£å†³**: åˆ†å±‚åˆ†æï¼ˆStratified Analysisï¼‰

**7. æˆæœ¬ä¸å¯¹ç§°ï¼ˆCost Asymmetryï¼‰**
- **é—®é¢˜**: æ–°æ¨¡å‹æˆæœ¬é«˜ï¼ˆå¦‚Kimié•¿æ–‡æœ¬Â¥24/ç™¾ä¸‡tokensï¼‰
- **è§£å†³**: **æˆæœ¬çº¦æŸä¸‹çš„æ•ˆæœæœ€å¤§åŒ–**ï¼ˆROIå¯¼å‘ï¼‰

---

## 2. å­—èŠ‚è·³åŠ¨ABå®éªŒå¹³å° DataTester

### 2.1 å¹³å°è§„æ¨¡ä¸èƒ½åŠ›

**æ•°æ®è§„æ¨¡**ï¼ˆ[æ®å­—èŠ‚æ•°æ®å¹³å°2024](https://www.cnblogs.com/bytedata/p/17999746)ï¼‰:
- **ç´¯è®¡å®éªŒ**: 240ä¸‡+
- **æ—¥æ–°å¢å®éªŒ**: 4000+
- **å¹¶å‘è¿è¡Œ**: 5ä¸‡+
- **è¦†ç›–åœºæ™¯**: æ¨èã€å¹¿å‘Šã€æœç´¢ã€UIã€äº§å“åŠŸèƒ½

**æŠ€æœ¯æ¶æ„**:

```mermaid
graph TB
    A[DataTesteræ ¸å¿ƒèƒ½åŠ›] --> B[å®éªŒè®¾è®¡]
    A --> C[æµé‡åˆ†é…]
    A --> D[æŒ‡æ ‡è®¡ç®—]
    A --> E[ç»Ÿè®¡åˆ†æ]

    B --> B1[å¤šå˜é‡å®éªŒ<br/>Factorial Design]
    B --> B2[åˆ†å±‚å®éªŒ<br/>Stratified]
    B --> B3[å¤šè‡‚è€è™æœº<br/>MAB]

    C --> C1[å“ˆå¸Œåˆ†æ¡¶<br/>Hash Bucketing]
    C --> C2[æ­£äº¤åˆ†æµ<br/>Orthogonal Traffic]
    C --> C3[å¤šå±‚å®éªŒ<br/>Layered Experiments]

    D --> D1[å®æ—¶æŒ‡æ ‡<br/>Real-time Metrics]
    D --> D2[é•¿æœŸæŒ‡æ ‡<br/>Long-term Metrics]
    D --> D3[è‡ªå®šä¹‰æŒ‡æ ‡<br/>Custom Metrics]

    E --> E1[Tæ£€éªŒ<br/>T-test]
    E --> E2[è´å¶æ–¯åˆ†æ<br/>Bayesian]
    E --> E3[CUPED<br/>Variance Reduction]
```

### 2.2 DataTester vs LaunchDarklyå¯¹æ¯”

| ç»´åº¦ | ByteDance DataTester | LaunchDarkly | Statsig | GrowthBook |
|------|---------------------|--------------|---------|------------|
| **å®šä»·** | æŒ‰éœ€å®šåˆ¶ï¼ˆä¼ä¸šï¼‰ | $20-75/å¸­ä½/æœˆ | å…è´¹+ä¼ä¸šç‰ˆ | å¼€æºå…è´¹ |
| **ä¸­æ–‡æ”¯æŒ** | â˜…â˜…â˜…â˜…â˜… | â˜…â˜…â˜†â˜†â˜† | â˜…â˜…â˜…â˜†â˜† | â˜…â˜…â˜†â˜†â˜† |
| **MABç®—æ³•** | Thompson Sampling | åŸºç¡€æ”¯æŒ | â˜…â˜…â˜…â˜…â˜… | æ”¯æŒ |
| **ä»“åº“åŸç”Ÿ** | éƒ¨åˆ†æ”¯æŒ | âŒ | â˜…â˜…â˜…â˜…â˜… | â˜…â˜…â˜…â˜…â˜† |
| **AIé…ç½®** | â˜…â˜…â˜…â˜…â˜† | â˜…â˜…â˜…â˜…â˜… | â˜…â˜…â˜…â˜…â˜† | â˜…â˜…â˜…â˜†â˜† |
| **ç§æœ‰éƒ¨ç½²** | â˜…â˜…â˜…â˜…â˜… | ä»˜è´¹ä¼ä¸šç‰ˆ | âŒ | â˜…â˜…â˜…â˜…â˜… |

**é€‰å‹å»ºè®®**:
- **å­—èŠ‚ç³»å…¬å¸**: DataTesterï¼ˆç«å±±å¼•æ“æä¾›ï¼‰
- **å›½é™…åŒ–å›¢é˜Ÿ**: LaunchDarklyï¼ˆç”Ÿæ€å®Œå–„ï¼‰
- **æˆæœ¬æ•æ„Ÿ**: Statsigå…è´¹ç‰ˆ or GrowthBookå¼€æº
- **æ•°æ®ä¸»æƒ**: GrowthBookè‡ªæ‰˜ç®¡

---

## 3. å¤šè‡‚è€è™æœºï¼ˆMulti-Armed Banditï¼‰

### 3.1 MAB vs ä¼ ç»ŸABæµ‹è¯•

**ç»å…¸å¤šè‡‚è€è™æœºé—®é¢˜**ï¼ˆ[æ®Medium MABæ•™ç¨‹](https://yaoyaowd.medium.com/%E4%BB%8Ethompson-sampling%E5%88%B0%E5%A2%9E%E5%BC%BA%E5%AD%A6%E4%B9%A0-%E5%86%8D%E8%B0%88%E5%A4%9A%E8%87%82%E8%80%81%E8%99%8E%E6%9C%BA%E9%97%AE%E9%A2%98-23a48953bd30)ï¼‰:

> èµŒåœºæœ‰Kå°è€è™æœºï¼Œæ¯å°ä¸­å¥–æ¦‚ç‡æœªçŸ¥ã€‚ä½ æœ‰Næ¬¡æ‹‰æ†æœºä¼šï¼Œå¦‚ä½•æœ€å¤§åŒ–æ€»æ”¶ç›Šï¼Ÿ

**æ ¸å¿ƒçŸ›ç›¾**: **æ¢ç´¢ï¼ˆExplorationï¼‰vs åˆ©ç”¨ï¼ˆExploitationï¼‰**

| ç­–ç•¥ | æ¢ç´¢ï¼ˆExplorationï¼‰ | åˆ©ç”¨ï¼ˆExploitationï¼‰ | é—æ†¾å€¼ï¼ˆRegretï¼‰ |
|------|-------------------|---------------------|-----------------|
| **çº¯æ¢ç´¢** | 100%ï¼ˆå‡åŒ€è¯•æ¢ï¼‰ | 0% | é«˜ |
| **çº¯åˆ©ç”¨** | 0%ï¼ˆåªæ‹‰å½“å‰æœ€ä¼˜ï¼‰ | 100% | é«˜ï¼ˆå¯èƒ½é”™è¿‡çœŸæ­£æœ€ä¼˜ï¼‰ |
| **Epsilon-Greedy** | Îµ%ï¼ˆå¦‚10%ï¼‰ | (1-Îµ)% | ä¸­ |
| **UCB** | åŠ¨æ€ï¼ˆç½®ä¿¡ä¸Šç•Œï¼‰ | åŠ¨æ€ | ä½ |
| **Thompson Sampling** | åŠ¨æ€ï¼ˆè´å¶æ–¯ï¼‰ | åŠ¨æ€ | **æœ€ä¼˜ï¼ˆæ¸è¿‘ï¼‰** |

**é—æ†¾å€¼ï¼ˆRegretï¼‰å®šä¹‰**:

```
Regret = Î£(æœ€ä¼˜è‡‚æœŸæœ›æ”¶ç›Š - å®é™…é€‰æ‹©è‡‚æ”¶ç›Š)
ç›®æ ‡: Minimize Regret
```

### 3.2 Thompson Samplingç®—æ³•

**åŸç†**ï¼ˆ[æ®DoorDash 2025](https://careersatdoordash.com/blog/experimentation-at-doordash-with-a-multi-armed-bandit-platform/)ï¼‰:
- **è¡Œä¸šæœ€æµè¡Œ**çš„MABç®—æ³•
- **è´å¶æ–¯æ–¹æ³•**ï¼šç»´æŠ¤æ¯ä¸ªè‡‚çš„åéªŒåˆ†å¸ƒ
- **æ¸è¿‘æœ€ä¼˜**ï¼šç†è®ºä¿è¯æœ€å°é—æ†¾å€¼
- **å¯¹å»¶è¿Ÿåé¦ˆé²æ£’**ï¼šæ‰¹é‡å¥–åŠ±è®¡ç®—

**ä¼ªä»£ç **:

```python
# Thompson Sampling for AI Model Selection

import numpy as np
from scipy.stats import beta

class ThompsonSamplingMAB:
    """
    å¤šè‡‚è€è™æœº - Thompson Samplingç®—æ³•
    ç”¨äºAIæ¨¡å‹åŠ¨æ€æµé‡åˆ†é…
    """
    def __init__(self, n_models=3):
        """
        Args:
            n_models: æ¨¡å‹æ•°é‡ï¼ˆå¦‚Qwen2.5, Qwen3, ERNIEï¼‰
        """
        self.n_models = n_models
        self.successes = np.ones(n_models)  # æˆåŠŸæ¬¡æ•°ï¼ˆåˆå§‹åŒ–ä¸º1ï¼ŒBetaå…ˆéªŒï¼‰
        self.failures = np.ones(n_models)  # å¤±è´¥æ¬¡æ•°

    def select_model(self):
        """
        é€‰æ‹©æ¨¡å‹ï¼ˆæ ¹æ®Thompson Samplingï¼‰

        Returns:
            int: é€‰ä¸­çš„æ¨¡å‹ç´¢å¼•
        """
        # ä»æ¯ä¸ªæ¨¡å‹çš„BetaåéªŒåˆ†å¸ƒä¸­é‡‡æ ·
        samples = [beta.rvs(self.successes[i], self.failures[i])
                   for i in range(self.n_models)]

        # é€‰æ‹©é‡‡æ ·å€¼æœ€å¤§çš„æ¨¡å‹
        return np.argmax(samples)

    def update(self, model_id, reward):
        """
        æ›´æ–°æ¨¡å‹åéªŒåˆ†å¸ƒï¼ˆæ”¶åˆ°ç”¨æˆ·åé¦ˆåï¼‰

        Args:
            model_id: æ¨¡å‹ç´¢å¼•
            reward: å¥–åŠ±ï¼ˆ1=æ»¡æ„ï¼Œ0=ä¸æ»¡æ„ï¼‰
        """
        if reward == 1:
            self.successes[model_id] += 1
        else:
            self.failures[model_id] += 1

    def get_win_probability(self):
        """
        è·å–æ¯ä¸ªæ¨¡å‹çš„èƒœç‡ä¼°è®¡

        Returns:
            np.array: æ¯ä¸ªæ¨¡å‹çš„æœŸæœ›èƒœç‡
        """
        return self.successes / (self.successes + self.failures)

# æ¨¡æ‹Ÿå®éªŒ: 3ä¸ªAIæ¨¡å‹åŠ¨æ€æµé‡åˆ†é…
mab = ThompsonSamplingMAB(n_models=3)

# æ¨¡å‹çœŸå®æ€§èƒ½ï¼ˆæœªçŸ¥ï¼‰
true_performance = [0.75, 0.82, 0.68]  # Qwen2.5: 75%, Qwen3: 82%, ERNIE: 68%

# è¿è¡Œ10000æ¬¡äº¤äº’
for t in range(10000):
    # é€‰æ‹©æ¨¡å‹
    chosen_model = mab.select_model()

    # æ¨¡æ‹Ÿç”¨æˆ·åé¦ˆï¼ˆæ ¹æ®çœŸå®æ€§èƒ½ï¼‰
    reward = 1 if np.random.rand() < true_performance[chosen_model] else 0

    # æ›´æ–°åéªŒ
    mab.update(chosen_model, reward)

    # æ¯1000æ¬¡è¾“å‡ºä¸€æ¬¡çŠ¶æ€
    if (t+1) % 1000 == 0:
        win_prob = mab.get_win_probability()
        print(f"Round {t+1}: Win Prob = {win_prob}, Best Model = {np.argmax(win_prob)}")

# è¾“å‡ºç¤ºä¾‹:
# Round 1000: Win Prob = [0.74 0.80 0.69], Best Model = 1
# Round 2000: Win Prob = [0.75 0.81 0.68], Best Model = 1
# ...
# Round 10000: Win Prob = [0.750 0.820 0.680], Best Model = 1 (Qwen3èƒœå‡º)
```

### 3.3 MAB vs ABæµ‹è¯•ï¼šä½•æ—¶é€‰æ‹©MABï¼Ÿ

| åœºæ™¯ | é€‰æ‹©ABæµ‹è¯• | é€‰æ‹©MAB |
|------|-----------|---------|
| **å†³ç­–ç±»å‹** | é•¿æœŸã€é‡å¤§å†³ç­–ï¼ˆå¦‚é‡æ„ï¼‰ | æŒç»­ä¼˜åŒ–ã€çŸ­æœŸå†³ç­– |
| **æµé‡æŸå¤±å®¹å¿åº¦** | å¯æ¥å—ï¼ˆç»Ÿè®¡ä¸¥è°¨æ€§ä¼˜å…ˆï¼‰ | ä¸å¯æ¥å—ï¼ˆæœ€å°åŒ–é—æ†¾ï¼‰ |
| **å˜ä½“æ•°é‡** | 2-5ä¸ª | >5ä¸ªï¼ˆMABé«˜æ•ˆæ¢ç´¢ï¼‰ |
| **ä¸šåŠ¡ç†è§£** | æ˜ç¡®å‡è®¾ã€éœ€éªŒè¯å› æœ | é»‘ç›’ä¼˜åŒ–ã€å…³æ³¨ç»“æœ |
| **ç›‘ç®¡è¦æ±‚** | é«˜ï¼ˆåŒ»ç–—ã€é‡‘èï¼‰ | ä½ï¼ˆå¹¿å‘Šã€æ¨èï¼‰ |
| **æ¡ˆä¾‹** | Qwen3 vs Qwen2.5ï¼ˆæ¨¡å‹åˆ‡æ¢ï¼‰ | 20ç§Promptå˜ä½“ä¼˜é€‰ |

**MABå…¸å‹åº”ç”¨**:
1. **ä¸ªæ€§åŒ–æ¨è**: ä¸ºæ¯ä¸ªç”¨æˆ·åŠ¨æ€é€‰æ‹©æœ€ä¼˜æ¨¡å‹
2. **å¹¿å‘Šåˆ›æ„ä¼˜åŒ–**: 20ç§æ–‡æ¡ˆå¿«é€Ÿæ”¶æ•›åˆ°Top 3
3. **Promptå·¥ç¨‹**: 100ç§Promptæ¨¡æ¿è‡ªåŠ¨ç­›é€‰

---

## 4. ç°åº¦å‘å¸ƒï¼ˆCanary Deploymentï¼‰

### 4.1 ç°åº¦å‘å¸ƒæµç¨‹

**å®šä¹‰**ï¼ˆ[æ®é˜¿é‡Œäº‘](https://help.aliyun.com/zh/ack/ack-managed-and-ack-dedicated/user-guide/use-kruise-rollout-to-perform-canary-releases-and-a-b-testing)ï¼‰:
ç°åº¦å‘å¸ƒï¼ˆCanary Releaseï¼‰ï¼Œåˆç§°é‡‘ä¸é›€å‘å¸ƒï¼ŒæŒ‡åœ¨ç”Ÿäº§ç¯å¢ƒä¸­é€æ­¥å°†æµé‡ä»æ—§ç‰ˆæœ¬åˆ‡æ¢åˆ°æ–°ç‰ˆæœ¬ï¼ŒåŒæ—¶ç›‘æ§å…³é”®æŒ‡æ ‡ï¼Œå‡ºç°é—®é¢˜ç«‹å³å›æ»šã€‚

**æ ‡å‡†æµç¨‹**ï¼ˆ[æ®Dataforest AI](https://dataforest.ai/glossary/canary-deployment)ï¼‰:

```
1% â†’ ç›‘æ§1å°æ—¶ â†’ 5% â†’ ç›‘æ§4å°æ—¶ â†’ 20% â†’ ç›‘æ§1å¤© â†’ 50% â†’ 100%

æ¯ä¸ªé˜¶æ®µé—¨æ§æ¡ä»¶ï¼ˆGating Criteriaï¼‰:
- å»¶è¿Ÿå¢å¹… < 10%
- è½¬åŒ–ç‡é™å¹… < 1%
- é”™è¯¯ç‡å¢å¹… < 0.5%
- CSATä¸é™ä½

è§¦å‘è‡ªåŠ¨å›æ»šï¼ˆAuto Rollbackï¼‰:
- å»¶è¿Ÿ > +10%
- è½¬åŒ–ç‡ < -1%
- 5xxé”™è¯¯ç‡ > 5%
```

**æ¶æ„å›¾**:

```mermaid
graph TB
    A[ç”¨æˆ·æµé‡100%] --> B{æµé‡åˆ†é…<br/>Nginx/ALB}
    B -->|99%| C[æ—§æ¨¡å‹v1.0<br/>Qwen2.5]
    B -->|1%| D[æ–°æ¨¡å‹v2.0<br/>Qwen3]

    C --> E[ç›‘æ§ç³»ç»Ÿ<br/>Prometheus]
    D --> E

    E --> F{æŒ‡æ ‡OK?}
    F -->|æ˜¯| G[å¢åŠ æµé‡è‡³5%]
    F -->|å¦| H[è‡ªåŠ¨å›æ»š<br/>100%æµé‡â†’v1.0]

    G --> I{ç»§ç»­ç›‘æ§}
    I -->|é€šè¿‡| J[20% â†’ 50% â†’ 100%]
    I -->|å¤±è´¥| H
```

### 4.2 Kruise Rolloutï¼ˆä¸­å›½å¼€æºæ–¹æ¡ˆï¼‰

**OpenKruise**ï¼ˆ[æ®é˜¿é‡Œäº‘æ–‡æ¡£](https://help.aliyun.com/zh/ack/ack-managed-and-ack-dedicated/user-guide/use-kruise-rollout-to-perform-canary-releases-and-a-b-testing)ï¼‰:
- é˜¿é‡Œäº‘å¼€æºçš„æ¸è¿›å¼äº¤ä»˜æ¡†æ¶
- æ”¯æŒ**é‡‘ä¸é›€å‘å¸ƒ**ã€**è“ç»¿éƒ¨ç½²**ã€**A/Bæµ‹è¯•**
- KubernetesåŸç”Ÿï¼Œé€‚åˆäº‘åŸç”ŸAIåº”ç”¨

**é…ç½®ç¤ºä¾‹**:

```yaml
# Kruise Rollouté…ç½®ï¼ˆAIæ¨¡å‹ç°åº¦ï¼‰
apiVersion: rollouts.kruise.io/v1alpha1
kind: Rollout
metadata:
  name: qwen3-canary-rollout
spec:
  objectRef:
    workloadRef:
      apiVersion: apps/v1
      kind: Deployment
      name: qwen3-inference
  strategy:
    canary:
      steps:
        - traffic: 1%  # é˜¶æ®µ1: 1%æµé‡
          pause:
            duration: 3600  # ç›‘æ§1å°æ—¶
        - traffic: 5%  # é˜¶æ®µ2: 5%æµé‡
          pause:
            duration: 14400  # ç›‘æ§4å°æ—¶
        - traffic: 20%  # é˜¶æ®µ3: 20%æµé‡
          pause:
            duration: 86400  # ç›‘æ§1å¤©
        - traffic: 50%
        - traffic: 100%

      trafficRoutings:
        - service: qwen-inference-service
          ingress:
            classType: nginx
            name: qwen-ingress

      # è‡ªåŠ¨å›æ»šæ¡ä»¶
      failurePolicy:
        metrics:
          - name: latency_p99
            thresholdRange:
              max: 2200  # å»¶è¿ŸP99 < 2.2sï¼ˆ+10%åŸºçº¿ï¼‰
          - name: error_rate_5xx
            thresholdRange:
              max: 0.05  # 5xxé”™è¯¯ç‡ < 5%
          - name: csat_score
            thresholdRange:
              min: 4.0  # CSAT >= 4.0/5
```

### 4.3 ç°åº¦å‘å¸ƒç›‘æ§çœ‹æ¿

**å…³é”®æŒ‡æ ‡**ï¼ˆReal-time Dashboardï¼‰:

```python
# ç°åº¦å‘å¸ƒç›‘æ§ç¤ºä¾‹ï¼ˆPrometheus + Grafanaï¼‰
import prometheus_client as prom
from datetime import datetime

# å®šä¹‰ç›‘æ§æŒ‡æ ‡
canary_traffic_ratio = prom.Gauge('canary_traffic_ratio', 'Canary traffic percentage')
canary_latency_p99 = prom.Histogram('canary_latency_p99', 'Canary P99 latency (ms)')
canary_error_rate = prom.Gauge('canary_error_rate', 'Canary 5xx error rate')
canary_csat = prom.Gauge('canary_csat', 'Canary CSAT score')

# æ¨¡æ‹Ÿç›‘æ§æ•°æ®ä¸ŠæŠ¥
def monitor_canary_stage(stage, traffic_percent):
    """
    ç›‘æ§ç°åº¦é˜¶æ®µå…³é”®æŒ‡æ ‡

    Args:
        stage: é˜¶æ®µåç§°ï¼ˆå¦‚"1%", "5%", "20%"ï¼‰
        traffic_percent: å½“å‰æµé‡æ¯”ä¾‹
    """
    canary_traffic_ratio.set(traffic_percent)

    # ä»PrometheusæŸ¥è¯¢å®æ—¶æŒ‡æ ‡
    latency = query_prometheus("histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))")
    error_rate = query_prometheus("rate(http_requests_total{status=~'5..'}[5m])")
    csat = query_prometheus("avg(csat_score[1h])")

    canary_latency_p99.observe(latency)
    canary_error_rate.set(error_rate)
    canary_csat.set(csat)

    # é—¨æ§æ£€æŸ¥
    baseline_latency = 2000  # ms
    if latency > baseline_latency * 1.1:  # +10%
        print(f"ğŸš¨ [STAGE {stage}] å»¶è¿Ÿè¶…æ ‡: {latency:.0f}ms > {baseline_latency*1.1:.0f}ms â†’ è§¦å‘å›æ»š")
        rollback_canary()
    elif error_rate > 0.05:
        print(f"ğŸš¨ [STAGE {stage}] é”™è¯¯ç‡è¶…æ ‡: {error_rate:.2%} > 5% â†’ è§¦å‘å›æ»š")
        rollback_canary()
    elif csat < 4.0:
        print(f"ğŸš¨ [STAGE {stage}] CSATè¿‡ä½: {csat:.2f} < 4.0 â†’ è§¦å‘å›æ»š")
        rollback_canary()
    else:
        print(f"âœ… [STAGE {stage}] æ‰€æœ‰æŒ‡æ ‡æ­£å¸¸ï¼Œç»§ç»­ä¸‹ä¸€é˜¶æ®µ")

def rollback_canary():
    """è‡ªåŠ¨å›æ»šåˆ°æ—§ç‰ˆæœ¬"""
    # é€šè¿‡Kubernetes APIä¿®æ”¹æµé‡æƒé‡
    k8s_client.patch_ingress("qwen-ingress", traffic_new=0, traffic_old=100)
    send_alert_to_feishu("ç°åº¦å‘å¸ƒå¤±è´¥ï¼Œå·²è‡ªåŠ¨å›æ»š")
```

---

## 5. å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹1: é€šä¹‰åƒé—®Qwen3ç°åº¦ä¸Šçº¿

**èƒŒæ™¯**:
- æ—¶é—´: 2025å¹´12æœˆ
- äº§å“: é€šä¹‰åƒé—®APIæœåŠ¡
- ç›®æ ‡: Qwen2.5-72B â†’ Qwen3-Maxå¹³æ»‘åˆ‡æ¢

**ç°åº¦ç­–ç•¥**:

| é˜¶æ®µ | æµé‡æ¯”ä¾‹ | æŒç»­æ—¶é—´ | ç›‘æ§æŒ‡æ ‡ | ç»“æœ |
|------|---------|---------|---------|------|
| **é˜¶æ®µ1** | 1% | 6å°æ—¶ | å¹»è§‰ç‡4.8% âœ… | é€šè¿‡ |
| **é˜¶æ®µ2** | 5% | 24å°æ—¶ | TTFT 1.9s âœ… | é€šè¿‡ |
| **é˜¶æ®µ3** | 20% | 3å¤© | CSAT 4.3 âœ… | é€šè¿‡ |
| **é˜¶æ®µ4** | 50% | 5å¤© | æˆæœ¬-17% âœ… | é€šè¿‡ |
| **é˜¶æ®µ5** | 100% | - | å…¨é‡ä¸Šçº¿ | âœ… |

**å…³é”®å†³ç­–ç‚¹**:
- **Day 2**: é˜¶æ®µ1â†’2æ—¶ï¼Œå‘ç°æŸå‚ç›´è¡Œä¸šï¼ˆæ³•å¾‹å’¨è¯¢ï¼‰å‡†ç¡®ç‡ä¸‹é™3%
- **åº”å¯¹**: æš‚åœç°åº¦ï¼Œä¸ºæ³•å¾‹åœºæ™¯å•ç‹¬å¾®è°ƒPromptï¼Œé‡æ–°æµ‹è¯•
- **ç»“æœ**: æ³•å¾‹åœºæ™¯å‡†ç¡®ç‡æ¢å¤ï¼Œç»§ç»­ç°åº¦

**ROI**:
- ç°åº¦å‘¨æœŸ: 13å¤©
- é¿å…å…¨é‡ä¸Šçº¿é£é™©: å¦‚ç›´æ¥100%åˆ‡æ¢ï¼Œå¯èƒ½å½±å“æ•°ç™¾ä¸‡ç”¨æˆ·
- æˆæœ¬èŠ‚çœ: æå‰å‘ç°æ³•å¾‹åœºæ™¯é—®é¢˜ï¼ŒèŠ‚çœå®¢è¯‰å¤„ç†æˆæœ¬

---

### æ¡ˆä¾‹2: å­—èŠ‚æ¨èç³»ç»ŸMABå®éªŒ

**èƒŒæ™¯**ï¼ˆ[æ®å­—èŠ‚æ•°æ®å¹³å°](https://www.cnblogs.com/bytedata/p/17999746)ï¼‰:
- äº§å“: æŠ–éŸ³æ¨èç®—æ³•
- é—®é¢˜: 10ä¸ªæ–°æ¨èæ¨¡å‹ï¼Œå¦‚ä½•å¿«é€Ÿç­›é€‰Top 1ï¼Ÿ
- ä¼ ç»ŸABæµ‹è¯•: éœ€10Ã—2å‘¨=20å‘¨ï¼ˆ5ä¸ªæœˆï¼‰

**MABæ–¹æ¡ˆ**:

```python
# æŠ–éŸ³æ¨èæ¨¡å‹å¤šè‡‚è€è™æœºå®éªŒ

models = [f"Model_{i}" for i in range(1, 11)]  # 10ä¸ªå€™é€‰æ¨¡å‹
mab = ThompsonSamplingMAB(n_models=10)

# çœŸå®CTRï¼ˆæœªçŸ¥ï¼‰
true_ctr = [0.08, 0.12, 0.09, 0.11, 0.15, 0.10, 0.09, 0.13, 0.08, 0.14]
#           M1    M2    M3    M4    M5    M6    M7    M8    M9    M10
#                                   â†‘æœ€ä¼˜

# æ¨¡æ‹Ÿ100ä¸‡æ¬¡æ¨è
traffic_distribution = np.zeros(10)

for impression in range(1000000):
    chosen_model = mab.select_model()
    traffic_distribution[chosen_model] += 1

    # æ¨¡æ‹Ÿç”¨æˆ·ç‚¹å‡»
    clicked = 1 if np.random.rand() < true_ctr[chosen_model] else 0
    mab.update(chosen_model, reward=clicked)

    # æ¯10ä¸‡æ¬¡è¾“å‡ºä¸€æ¬¡çŠ¶æ€
    if (impression+1) % 100000 == 0:
        top3_models = np.argsort(mab.get_win_probability())[-3:][::-1]
        print(f"[{impression+1}æ¬¡æ¨è] Top 3: {top3_models}, æµé‡åˆ†å¸ƒ: {traffic_distribution/traffic_distribution.sum():.3f}")

# è¾“å‡ºç¤ºä¾‹:
# [100000æ¬¡æ¨è] Top 3: [4 9 7], æµé‡åˆ†å¸ƒ: [0.05 0.08 0.06 0.07 0.25 0.07 0.06 0.12 0.05 0.19]
# [1000000æ¬¡æ¨è] Top 3: [4 9 7], æµé‡åˆ†å¸ƒ: [0.02 0.03 0.02 0.03 0.45 0.03 0.02 0.15 0.02 0.23]
#                                                     â†‘ Model5ï¼ˆCTR 15%ï¼‰è·å¾—45%æµé‡
```

**å®éªŒç»“æœ**:
- **æ—¶é—´ç¼©çŸ­**: 100ä¸‡æ¬¡æ¨èåæ”¶æ•›ï¼ˆçº¦**2å‘¨**ï¼‰ï¼Œç›¸æ¯”ä¼ ç»ŸABèŠ‚çœ**18å‘¨**
- **æµé‡æŸå¤±**: MABæœ€å°åŒ–é—æ†¾å€¼ï¼Œç›¸æ¯”å‡åŒ€åˆ†é…ABæµ‹è¯•èŠ‚çœ**8%æµé‡æµªè´¹**
- **æœ€ç»ˆå†³ç­–**: Model 5ï¼ˆCTR 15%ï¼‰èƒœå‡ºï¼Œå…¨é‡ä¸Šçº¿

---

## 6. æœ€ä½³å®è·µæ€»ç»“

### 6.1 ABæµ‹è¯•é»„é‡‘æ³•åˆ™

**1. æ˜ç¡®å‡è®¾**ï¼ˆHypothesis-Drivenï¼‰
- âŒ "è¯•è¯•Qwen3æ•ˆæœå¦‚ä½•"
- âœ… "Qwen3å°†ä½¿å¹»è§‰ç‡ä»6.5%é™è‡³<5%ï¼ˆ-23%ï¼‰ï¼ŒCSATæå‡è‡³4.3ï¼ˆ+5%ï¼‰"

**2. æ ·æœ¬é‡è®¡ç®—**ï¼ˆPower Analysisï¼‰
```python
from statsmodels.stats.power import tt_ind_solve_power

# è®¡ç®—æœ€å°æ ·æœ¬é‡
n = tt_ind_solve_power(
    effect_size=0.2,  # Cohen's dï¼ˆå°=0.2ï¼Œä¸­=0.5ï¼Œå¤§=0.8ï¼‰
    alpha=0.05,  # æ˜¾è‘—æ€§æ°´å¹³ï¼ˆ5%ï¼‰
    power=0.8,  # ç»Ÿè®¡åŠŸæ•ˆï¼ˆ80%ï¼‰
    ratio=1.0  # å®éªŒç»„:å¯¹ç…§ç»„=1:1
)
print(f"æ¯ç»„éœ€è¦æ ·æœ¬é‡: {int(n)}")  # è¾“å‡º: æ¯ç»„éœ€è¦æ ·æœ¬é‡: 394
```

**3. æå‰åœæ­¢è§„åˆ™**ï¼ˆEarly Stoppingï¼‰
- âœ… **æ˜æ˜¾å¤±è´¥**: å¦‚Qwen3å¹»è§‰ç‡æš´æ¶¨è‡³15%ï¼Œç«‹å³åœæ­¢
- âŒ **è¿‡æ—©èƒœåˆ©å®£å‘Š**: éœ€æ»¡è¶³é¢„è®¾æ ·æœ¬é‡+æ—¶é—´ï¼Œé¿å…"å·çœ‹"å¯¼è‡´å‡é˜³æ€§

**4. åˆ†å±‚åˆ†æ**ï¼ˆSegmentationï¼‰
- æŒ‰ç”¨æˆ·ç±»å‹ï¼ˆæ–°ç”¨æˆ· vs è€ç”¨æˆ·ï¼‰
- æŒ‰åœºæ™¯ï¼ˆèŠå¤© vs æ–‡æ¡£åˆ†æï¼‰
- æŒ‰è®¾å¤‡ï¼ˆç§»åŠ¨ vs PCï¼‰

**5. é•¿æœŸæ•ˆåº”**ï¼ˆLong-term Impactï¼‰
- è§‚å¯Ÿç•™å­˜ç‡ã€LTVï¼ˆCustomer Lifetime Valueï¼‰
- è­¦æƒ•æ–°å¥‡æ•ˆåº”ï¼ˆNovelty Effectï¼‰

### 6.2 é€‰å‹å†³ç­–æ ‘

```python
def choose_experimentation_method(scenario):
    """
    å®éªŒæ–¹æ³•é€‰å‹å†³ç­–æ ‘

    Args:
        scenario: åœºæ™¯æè¿°å­—å…¸

    Returns:
        str: æ¨èæ–¹æ³•
    """
    if scenario['risk'] == 'high':  # é«˜é£é™©ï¼ˆå¦‚é‡‘èã€åŒ»ç–—ï¼‰
        return "ç°åº¦å‘å¸ƒCanaryï¼ˆ1%â†’5%â†’20%â†’100%ï¼‰"

    elif scenario['variants_count'] > 5 and scenario['traffic_loss_tolerance'] == 'low':
        return "å¤šè‡‚è€è™æœºMABï¼ˆThompson Samplingï¼‰"

    elif scenario['decision_type'] == 'long_term' and scenario['hypothesis_clear'] == True:
        return "ä¼ ç»ŸABæµ‹è¯•ï¼ˆ7-14å¤©ï¼Œä¸¥è°¨ç»Ÿè®¡ï¼‰"

    elif scenario['feature_flags'] == True:
        return "Feature Flags + ABæµ‹è¯•ï¼ˆè§£è€¦éƒ¨ç½²ä¸å‘å¸ƒï¼‰"

    else:
        return "ä¼ ç»ŸABæµ‹è¯•ï¼ˆé»˜è®¤æ–¹æ¡ˆï¼‰"

# ç¤ºä¾‹åœºæ™¯
scenario_qwen3 = {
    'risk': 'medium',
    'variants_count': 2,  # Qwen2.5 vs Qwen3
    'traffic_loss_tolerance': 'medium',
    'decision_type': 'long_term',
    'hypothesis_clear': True,
    'feature_flags': False
}

print(choose_experimentation_method(scenario_qwen3))
# è¾“å‡º: "ä¼ ç»ŸABæµ‹è¯•ï¼ˆ7-14å¤©ï¼Œä¸¥è°¨ç»Ÿè®¡ï¼‰"
```

---

## 7. æœ¬ç« å°ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **AI ABæµ‹è¯•ç‰¹æ®Šæ€§**: éç‹¬ç«‹åŒåˆ†å¸ƒã€é«˜æ–¹å·®ã€å¤šç›®æ ‡ä¼˜åŒ–ï¼Œéœ€æ›´å¤§æ ·æœ¬é‡

2. **å­—èŠ‚DataTester**: 240ä¸‡+å®éªŒï¼Œ4000+æ–°å®éªŒ/å¤©ï¼Œæ”¯æŒå…¨åœºæ™¯

3. **MAB vs AB**: MABé€‚åˆ>5ä¸ªå˜ä½“ã€æŒç»­ä¼˜åŒ–åœºæ™¯ï¼ŒThompson Samplingæ¸è¿‘æœ€ä¼˜

4. **ç°åº¦å‘å¸ƒ**: 1%â†’5%â†’20%â†’100%æ¸è¿›ä¸Šçº¿ï¼Œè‡ªåŠ¨å›æ»šé˜ˆå€¼ï¼ˆå»¶è¿Ÿ+10% or è½¬åŒ–-1%ï¼‰

5. **å¹³å°é€‰å‹**: å­—èŠ‚ç³»é€‰DataTesterï¼Œå›½é™…é€‰Statsig/LaunchDarklyï¼Œå¼€æºé€‰GrowthBook

---

### é¢è¯•é«˜é¢‘è€ƒç‚¹

**åœºæ™¯é¢˜**: "10ä¸ªAIæ¨¡å‹éœ€è¦å¿«é€Ÿç­›é€‰Top 1ï¼Œå¦‚ä½•è®¾è®¡å®éªŒï¼Ÿ"
- ç­”æ¡ˆ: å¤šè‡‚è€è™æœºMABï¼ˆThompson Samplingï¼‰ï¼Œ2å‘¨å†…æ”¶æ•›

**å¯¹æ¯”é¢˜**: "MAB vs ä¼ ç»ŸABæµ‹è¯•çš„æ ¸å¿ƒå·®å¼‚ï¼Ÿ"
- ç­”æ¡ˆ: MABåŠ¨æ€æµé‡åˆ†é…æœ€å°åŒ–é—æ†¾ï¼ŒABå›ºå®šæµé‡ä¸¥è°¨ç»Ÿè®¡

**æŠ€æœ¯é¢˜**: "å¦‚ä½•æ£€æµ‹ABæµ‹è¯•ä¸­çš„è¾›æ™®æ£®æ‚–è®ºï¼Ÿ"
- ç­”æ¡ˆ: åˆ†å±‚åˆ†æï¼Œè§‚å¯Ÿæ•´ä½“è¶‹åŠ¿vså­ç»„è¶‹åŠ¿æ˜¯å¦ç›¸å

---

### æ‰©å±•é˜…è¯»

1. [å­—èŠ‚DataTesterå®˜æ–¹æ–‡æ¡£](https://www.volcengine.com/product/datatester) - ç«å±±å¼•æ“ABå®éªŒå¹³å°
2. [DoorDash MABå¹³å°](https://careersatdoordash.com/blog/experimentation-at-doordash-with-a-multi-armed-bandit-platform/) - Thompson Samplingåº”ç”¨
3. [Statsig vs LaunchDarklyå¯¹æ¯”](https://www.statsig.com/comparison/alternatives-to-launchdarkly-for-feature-flags) - ç‰¹å¾æ——å¸œå¹³å°é€‰å‹
4. [Kruise Rolloutæ–‡æ¡£](https://help.aliyun.com/zh/ack/ack-managed-and-ack-dedicated/user-guide/use-kruise-rollout-to-perform-canary-releases-and-a-b-testing) - é˜¿é‡Œäº‘ç°åº¦å‘å¸ƒ

---

## ä¸‹èŠ‚é¢„å‘Š

**Note 85**: AIä¼¦ç†ä¸åˆè§„ | AI Ethics & Compliance
- ä¸­å›½AIç›‘ç®¡ç¯å¢ƒï¼ˆç®—æ³•å¤‡æ¡ˆã€æ·±åº¦åˆæˆæ ‡è¯†ï¼‰
- æ•°æ®å®‰å…¨æ³•ã€ä¸ªä¿æ³•å¯¹AIäº§å“çš„å½±å“
- è´Ÿè´£ä»»AIè®¾è®¡åŸåˆ™
- åè§æ£€æµ‹ä¸å…¬å¹³æ€§è¯„ä¼°

**æ€è€ƒé¢˜**:
1. ä¸ºä»€ä¹ˆä¸­å›½AIäº§å“å¿…é¡»è´´"æ·±åº¦åˆæˆæ ‡è¯†"ï¼Ÿ
2. å¦‚ä½•åœ¨æ¨¡å‹æ€§èƒ½ä¸å…¬å¹³æ€§ä¹‹é—´å¹³è¡¡ï¼Ÿ

---

> **é‡‘å¥**: "ABæµ‹è¯•ä¸æ˜¯ä¸ºäº†è¯æ˜ä½ æ˜¯å¯¹çš„ï¼Œè€Œæ˜¯ä¸ºäº†å‘ç°ä½ é”™åœ¨å“ªé‡Œã€‚" â€”â€” å­—èŠ‚è·³åŠ¨å®éªŒæ–‡åŒ–
